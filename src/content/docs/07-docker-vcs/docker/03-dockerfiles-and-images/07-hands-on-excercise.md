---
title: Hands-Ons Excercise
---
## Hands-On Exercise: Containerizing a Simple Node.js App

> In this lab you’ll build a minimal Node.js web server, package it into a Docker image, and run it as a container. You’ll also learn good practices for image size, caching, and developer workflow.

---

## Learning Objectives

* Create a tiny HTTP server in Node.js that responds on port `3000`.
* Write a Dockerfile using an official Node base image.
* Build and run the app in a container and verify it at `http://localhost:3000`.
* Apply best practices: `.dockerignore`, non-root user, predictable dependency installs, caching, and health checks.
* (Optional) Use Compose for a one-command workflow and add live reload for development.

---

## Prerequisites

* **Installed:** Docker Engine or Docker Desktop (any OS), Node.js 18+ (only needed for local testing or dev extras).
* **Terminal skills:** Basic shell commands.
* **Ports:** Ensure port **3000** is free on your host.

---

## Project Layout

Create a new folder for the exercise:

```bash
mkdir hello-docker && cd hello-docker
```

Recommended structure:

```bash
hello-docker/
├─ app.js
├─ package.json
├─ package-lock.json        # generated by `npm install` (keep it!)
├─ Dockerfile
└─ .dockerignore
```

---

## 1) Create a Simple Node.js App

**`app.js`**

```js
// Minimal HTTP server on port 3000
const http = require('http');
const PORT = process.env.PORT || 3000;

const server = http.createServer((req, res) => {
  res.writeHead(200, { 'Content-Type': 'text/plain' });
  res.end('Hello, Docker!\n');
});

server.listen(PORT, () => {
  console.log(`Server is listening on port ${PORT}`);
});
```

**`package.json`**

```json
{
  "name": "hello-docker",
  "version": "1.0.0",
  "description": "Minimal Node.js app for Docker hands-on",
  "main": "app.js",
  "scripts": {
    "start": "node app.js"
  },
  "license": "MIT"
}
```

Install dependencies (none required here, but this will create a lockfile):

```bash
npm install
```

> **Why lockfiles matter:** The `package-lock.json` pins versions for reproducible builds and better Docker layer caching.

---

## 2) Write the Dockerfile

Start with a clean, fast, and secure base. Use `node:<version>-alpine` or `-slim`. Alpine is smaller; slim is Debian-based (broader compatibility).

**`Dockerfile` (production-ready, small footprint, non-root):**

```dockerfile
# 1) Use an official Node base image
FROM node:20-alpine AS base

# 2) Create and use a non-root user for better security
# - node image already provides a node user and group
WORKDIR /usr/src/app

# 3) Install dependencies separately for better caching
#    Copy only package files first, so Docker can reuse this layer if app code changes.
COPY package*.json ./

# Use npm ci when lockfile exists to ensure clean, reproducible installs
RUN npm ci --only=production

# 4) Copy application source
COPY app.js ./

# 5) Expose the port your app listens on (documentation hint for humans/tools)
EXPOSE 3000

# 6) Add a simple healthcheck (optional, useful in Compose/K8s)
HEALTHCHECK --interval=30s --timeout=3s CMD \
  wget -qO- http://localhost:3000 || exit 1

# 7) Use the non-root node user
USER node

# 8) Define the startup command
CMD ["node", "app.js"]
```

> **Caching tip:** By copying `package*.json` first and running `npm ci` before copying the rest of your source, you let Docker reuse the dependency layer when only your app code changes.

---

## 3) Ignore Unneeded Files

**`.dockerignore`**

```bash
# Node
node_modules
npm-debug.log
.DS_Store

# VCS
.git
.gitignore

# OS/editor junk
*.swp
*.log
```

This prevents large or irrelevant files from bloating your build context and image.

---

## 4) Build the Image

Run:

```bash
docker build -t hello-docker .
```

* `-t hello-docker` gives the image a friendly name (tag `latest` implied).
* If you change code and rebuild, Docker will leverage cached layers where possible.

---

## 5) Run the Container

Map container port **3000** to host port **3000**:

```bash
docker run --name hello-docker --rm -p 3000:3000 hello-docker
```

* `--rm` cleans up the container when it stops.
* `--name` gives it a predictable name (handy for logs/exec).
* You should see: `Server is listening on port 3000`.

**Verify:**

* Visit: `http://localhost:3000`
* Or via CLI:

  ```bash
  curl -i http://localhost:3000
  ```

Expected response:

```bash
HTTP/1.1 200 OK
Content-Type: text/plain
Hello, Docker!
```

Stop the container (in the same terminal) with `Ctrl+C` or from another terminal:

```bash
docker stop hello-docker
```

---

## 6) Inspect, Logs, and Cleanup

* List images: `docker images`
* List containers: `docker ps -a`
* View logs: `docker logs hello-docker`
* Remove image: `docker rmi hello-docker` (stop containers first)

---

## 7) Development Workflow (Optional Extras)

### A) Live Reload with `nodemon` (dev-only container)

Add a dev script and nodemon:

```bash
npm install --save-dev nodemon
```

Update `package.json`:

```json
"scripts": {
  "start": "node app.js",
  "dev": "nodemon --watch . app.js"
}
```

**Dev Dockerfile** (or a second stage) could include dev deps, but a simpler pattern is to run Node from your host and mount code into a lightweight container for parity. For pure Docker dev:

```bash
docker run --name hello-dev --rm -it \
  -p 3000:3000 \
  -v "$PWD":/usr/src/app \
  -w /usr/src/app node:20-alpine sh -c "npm ci && npx nodemon app.js"
```

This mounts your current directory and runs nodemon inside the container.

### B) Docker Compose for One-Command Up/Down

**`compose.yaml`**

```yaml
services:
  web:
    image: hello-docker
    build: .
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3000"]
      interval: 30s
      timeout: 3s
      retries: 3
```

Run:

```bash
docker compose up --build
# ... visit http://localhost:3000
docker compose down
```

---

## 8) Multi-Stage Build (Smaller Images)

If your app needs to compile native modules or transpile code, you can separate **build** and **runtime**:

```dockerfile
# Stage 1: Build (has compilers and full toolchain if needed)
FROM node:20-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build  # if you have a build step

# Stage 2: Runtime (copy only what you need)
FROM node:20-alpine AS runtime
WORKDIR /usr/src/app
COPY --from=build /app/package*.json ./
RUN npm ci --only=production
COPY --from=build /app/dist ./dist
EXPOSE 3000
USER node
CMD ["node", "dist/app.js"]
```

Benefits:

* Smaller attack surface.
* Faster deploys and pulls.

---

## 9) Tagging and (Optionally) Pushing to a Registry

Tag your image explicitly (e.g., semantic version):

```bash
docker tag hello-docker my-registry.example.com/hello-docker:1.0.0
docker push my-registry.example.com/hello-docker:1.0.0
```

> Replace with your registry URL and ensure you’re authenticated (`docker login`).

---

## 10) Common Pitfalls & Troubleshooting

* **Port already in use:**
  Error like `bind: address already in use` → change host port mapping (e.g., `-p 8080:3000`) or free up port 3000.

* **No response in browser:**
  Ensure app listens on `0.0.0.0` inside containers. (The sample uses Node’s default and works; frameworks sometimes default to `localhost`.)

* **Cache not being used:**
  If you change `package.json`, the dependency layer will rebuild. If only `app.js` changes, cache should be reused.

* **Missing `.dockerignore`:**
  Increases build context size and slows builds.

* **Running as root:**
  Avoid; use `USER node` or create a dedicated user in the image.

* **`npm install` vs `npm ci`:**
  Prefer `npm ci` when a lockfile exists for reproducible builds and better caching.

---

## 11) Validation Checklist

* [ ] `docker build -t hello-docker .` completes successfully.
* [ ] `docker run -p 3000:3000 hello-docker` logs “Server is listening on port 3000”.
* [ ] Visiting `http://localhost:3000` returns “Hello, Docker!”.
* [ ] Stopping the container and rebuilding after editing `app.js` is fast (cache in effect).
* [ ] Image uses a non-root user and includes a `.dockerignore`.

---

## 12) Stretch Goals (Optional)

* Add an environment variable (e.g., `MESSAGE`) and read it in `app.js`:

  ```bash
  docker run -e MESSAGE="Hi from env" -p 3000:3000 hello-docker
  ```

* Add structured JSON logging.

* Add a `/healthz` HTTP endpoint instead of a bare health check.

* Use `node:20-slim` and compare image size and cold start.

* Containerize a more realistic Express app with routes and static files.

---

## Quick Reference

**Build:**

```bash
docker build -t hello-docker .
```

**Run:**

```bash
docker run --name hello-docker --rm -p 3000:3000 hello-docker
```

**Verify:**

```bash
curl -i http://localhost:3000
```

**Stop:**

```bash
docker stop hello-docker
```

---

## Recap

You created a tiny Node.js server, wrote a Dockerfile with good practices (lockfile, caching, `.dockerignore`, non-root user, healthcheck), built the image, and ran it as a container. These techniques scale directly to larger Node.js services and CI/CD pipelines.
